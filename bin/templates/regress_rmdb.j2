<?xml version="1.0" ?>
<!-- Copyright 2023 Dolphin Design -->
<!-- SPDX-License-Identifier: Apache-2.0 WITH SHL-2.1 -->

{% import 'regress_macros.j2' as regress_macros -%}


<rmdb>

    <runnable name="{{project}}" type="group" sequential="yes">
        <parameters>
            <parameter name="results_sim_path">{{results_path}}/{{simulator}}_results</parameter>
        </parameters>
        <members>
{% for r in regressions %}
            <member>{{r.name}}</member>
{% endfor %}
            <member>report</member>
        </members>
    </runnable>


{% for r in regressions %}
    <runnable name="{{r.name}}" type="group" sequential="yes">
        <members>
{% for build in r.get_builds() %}
            <member>{{build.name}}</member>
{% endfor %}
        </members>
        <preScript launch="exec">
{% for b in r.get_builds_with_no_tests() %}
            <command> cd {{b.abs_dir}} &amp;&amp; {{b.cmd}} CV_CORE={{project}} CFG={{b.cfg}} CV_SIM_PREFIX= {{toolchain|upper}}=1 SIMULATOR={{b.simulator}} COV={{regress_macros.yesorno(b.cov)}} {{regress_macros.cv_results(results)}} {{makeargs}} </command>
{% endfor %}
        </preScript>
    </runnable>


{% for build in r.get_builds() %}
        <runnable name="{{build.name}}" type="group" sequential="no">
            <parameters>
                <parameter name="build_config">{{build.cfg}}</parameter>
{% if build.test_cfg is defined %}
                <parameter name="build_test_config">{{build.test_cfg}}</parameter>
{% endif %}
                <parameter name="build_name">{{build.name}}</parameter>
            </parameters>
            <members>
{% for t in r.get_tests_of_build(build.name) %}
                <member>{{t.name}}</member>
{% endfor %}
            </members>
            <preScript launch="exec">
                <command> cd {{build.abs_dir}} &amp;&amp; {{build.cmd}} CV_CORE={{project}} CFG={{build.cfg}} CV_SIM_PREFIX= {{toolchain|upper}}=1 SIMULATOR={{build.simulator}} USE_ISS={{regress_macros.yesorno(build.iss)}} COV={{regress_macros.yesorno(build.cov)}} {{regress_macros.cv_results(results)}} {{makeargs}} </command>
            </preScript>
        </runnable>

{% endfor %}


{% for k,t in unique_tests.items() %}
            <runnable name="{{t.name}}" type="task" repeat="{{t.num}}">
                <parameters>
{% if t.cfg is defined %}
                    <parameter name="t_cfg" >{{t.cfg}}</parameter>
{% else %}
                    <parameter name="t_cfg" >(%build_config%)</parameter>
{% endif %}
{% if t.test_cfg is defined %}
                    <parameter name="t_test_cfg"    >{{t.test_cfg}}</parameter>
                    <parameter name="ucdb_path"     >(%results_sim_path%)/(%t_cfg%)/{{t.testname}}/{{t.test_cfg}}/(%ITERATION%)</parameter>
                    <parameter name="ucdb_filename" >{{t.testname}}-{{t.test_cfg}}</parameter>
{% elif build.test_cfg is defined %}
                    <parameter name="t_test_cfg"    >{{build.test_cfg}}</parameter>
                    <parameter name="ucdb_path"     >(%results_sim_path%)/(%t_cfg%)/{{t.testname}}/{{build.test_cfg}}/(%ITERATION%)</parameter>
                    <parameter name="ucdb_filename" >{{t.testname}}-{{build.test_cfg}}</parameter>
{% else %}
                    <parameter name="t_test_cfg"    ></parameter>
                    <parameter name="ucdb_path"     >(%results_sim_path%)/(%t_cfg%)/{{t.testname}}/(%ITERATION%)</parameter>
                    <parameter name="ucdb_filename" >{{t.testname}}</parameter>
{% endif %}
{% if coverage != false %}
                    <parameter name="ucdbfile" >(%ucdb_path%)/(%ucdb_filename%).ucdb</parameter>
{% endif %}
                    <parameter name="log_file" >(%DATADIR%)/{{project}}/{{r.name}}/(%build_name%)/(%INSTANCE%)/execScript.log</parameter>
                </parameters>
{% if lsf != None %}
                <method name="grid" gridtype="lsf" action="execScript">
                    <command> {{lsf}} -P {{project}} -J (%RUNNABLE%) (%WRAPPER%) </command>
                </method>
{% endif %}
                <execScript launch="exec" usestderr="no">
                    <command> cd {{t.abs_dir}} &amp;&amp; {{t.cmd}} CHECK_SIM_RESULT={{regress_macros.yesorno(check_sim_results)}} CHECK_SIM_LOG=(%log_file%) COMP=0 CV_SIM_PREFIX= CV_CORE={{project}} {{toolchain|upper}}=1 CFG=(%t_cfg%) TEST_CFG_FILE=(%t_test_cfg%) RISCVDV_CFG={{t.riscvdv_cfg}} SIMULATOR={{t.simulator}} USE_ISS={{regress_macros.yesorno(t.iss)}} COV={{regress_macros.yesorno(t.cov)}} RUN_INDEX=(%ITERATION%) GEN_START_INDEX=(%ITERATION%) SEED=random {{regress_macros.cv_results(results)}} {{makeargs}} {{t.makearg}}</command>
                </execScript>
            </runnable>

{% endfor %}


{% endfor %}

    <!-- =========== Reporting =========== -->
    <runnable name="report" type="group">
        <parameters>
            <parameter name="merged_file">(%results_sim_path%)/merged/merged.ucdb</parameter>
            <!-- <parameter name="tplan_file">(%results_sim_path%)/merged.ucdb</parameter> -->
        </parameters>
{% if coverage != false %}
        <preScript launch="exec">
            <command> cd {{results_path}} &amp;&amp; make cov_merge SIMULATOR={{simulator}}</command>
        </preScript>
{% endif %}
        <members>
            <member>html_report</member>
        </members>
        <postScript mintimeout="3000">
            <command>vrun -vrmdata (%DATADIR%) -status -full -html -htmldir (%DATADIR%)/vrun</command>
        </postScript>
    </runnable>

        <runnable name="html_report" type="task">
            <execScript>
                <command> if {[file exists (%merged_file%)]} {vcover report -annotate -testdetails -details -html (%merged_file%) -output [file join {{results_path}} cov_html_summary]} </command>
            </execScript>
        </runnable>

</rmdb>
